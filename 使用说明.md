# 股票数据处理系统使用说明

## 概述

本系统用于下载和处理股票数据，包括日线数据下载、其他市场数据下载和技术指标计算。系统采用增量处理方式，只处理新增或缺失的数据，提高效率。

## 文件说明

### 核心脚本
- `main.py` - 主程序，执行完整的数据处理流程，支持多种运行模式
- `download_stock_daily_incremental.py` - 增量下载股票日线数据
- `download_other_data.py` - 下载其他市场数据（资金流向、龙虎榜、概念数据等）
- `process_stock_data_incremental.py` - 增量处理股票数据（计算技术指标）
- `logging_config.py` - 日志配置模块

### 功能模块

#### 1. 股票日线数据下载
- **脚本**: `download_stock_daily_incremental.py`
- **功能**: 增量下载股票日线数据和资金流数据
- **特点**: 只下载数据库中缺失的数据，提高效率

#### 2. 其他市场数据下载
- **脚本**: `download_other_data.py`
- **功能**: 下载各种市场数据
- **包含数据**:
  - 大盘资金流向数据 (`market_moneyflow`)
  - 板块资金流向数据 (`sector_moneyflow`)
  - 龙虎榜数据 (`top_list`)
  - 机构交易数据 (`top_inst`)
  - 概念成分股数据 (`concept_cons`)
  - 概念数据 (`concept_data`)
  - 各种股票排名数据

#### 3. 数据处理
- **脚本**: `process_stock_data_incremental.py`
- **功能**: 计算技术指标（KDJ、MACD、布林带等）
- **特点**: 增量处理，只处理新增数据

## 下载策略优化

### 新的下载策略：混合方案 + 批量下载

系统采用混合方案，结合了效率和完整性的优势：

#### 1. **混合方案**
- **默认模式**：只补全完全缺失的交易日（该日期没有任何股票数据）
- **定期校验**：建议定期（如每月）进行全量校验，补全个别缺失的股票-日期数据
- **优势**：避免重复下载，提高效率

#### 2. **批量下载策略**
- **按日期批量下载**：一次API调用下载整个交易日的所有股票数据
- **分别下载**：日线数据和资金流向数据分别批量下载，然后合并
- **优势**：大幅减少API调用次数，提高下载速度

### 优势对比

| 策略 | 优势 | 适用场景 |
|------|------|----------|
| **混合方案 + 批量下载** | 1. 减少API调用次数<br>2. 避免重复下载<br>3. 数据完整性更好<br>4. 处理速度更快<br>5. 智能缺失检测 | 推荐使用 |
| 逐个股票下载 | 1. 可以精确控制<br>2. 内存占用更少 | 特殊需求时使用 |

## 使用方法

### 1. 完整流程（默认）

```bash
# 正常模式运行完整流程
python main.py

# 安静模式运行完整流程
python main.py --log-level quiet

# 详细模式运行完整流程
python main.py --log-level verbose
```

### 2. 仅下载数据

```bash
# 仅下载股票日线数据
python main.py --download-only

# 安静模式仅下载数据
python main.py --download-only --log-level quiet
```

### 3. 仅处理数据

```bash
# 仅处理数据（计算技术指标）
python main.py --process-only

# 详细模式仅处理数据
python main.py --process-only --log-level verbose
```

### 4. 跳过其他市场数据下载

```bash
# 跳过其他市场数据下载
python main.py --skip-other-data

# 安静模式跳过其他数据下载
python main.py --skip-other-data --log-level quiet
```

### 5. 保存日志到文件

```bash
# 保存日志到文件
python main.py --log-file logs/process.log

# 安静模式并保存日志
python main.py --log-level quiet --log-file logs/process.log
```

### 6. 查看帮助

```bash
python main.py --help
```

## 命令行参数说明

| 参数 | 说明 | 示例 |
|------|------|------|
| `--log-level` | 日志级别：quiet/normal/verbose | `--log-level quiet` |
| `--log-file` | 日志文件路径 | `--log-file logs/process.log` |
| `--download-only` | 仅执行数据下载 | `--download-only` |
| `--process-only` | 仅执行数据处理 | `--process-only` |
| `--skip-other-data` | 跳过其他市场数据下载 | `--skip-other-data` |

## 执行流程

1. **步骤1**: 增量下载股票日线数据
2. **步骤2**: 下载其他市场数据（可选跳过）
3. **步骤3**: 增量处理股票数据（计算技术指标）

## 日志级别说明

### QUIET 模式
- 只显示警告和错误信息
- 适合后台运行或定时任务
- 输出最少，干扰最小

### NORMAL 模式（默认）
- 显示主要处理信息
- 显示进度和统计信息
- 适合日常使用

### VERBOSE 模式
- 显示所有详细信息
- 适合调试和问题排查
- 输出最多，信息最详细

## 日志优化说明

### 已优化的日志输出

1. **减少重复信息**：
   - 移除了"数据已完整，无需下载"等冗余日志
   - 只在有数据需要下载时显示信息

2. **静默处理重复键错误**：
   - 重复数据错误不再显示详细错误信息
   - 避免大量重复键错误的日志刷屏

3. **简化进度显示**：
   - 使用简洁的进度条
   - 减少不必要的详细日志

4. **第三方库日志控制**：
   - 自动设置第三方库的日志级别为WARNING
   - 减少SQLAlchemy、PyMySQL等库的调试信息

## 性能优化

### 增量处理优势

1. **智能缺失检测**：只下载完全缺失的交易日数据
2. **批量下载**：按日期批量下载所有股票数据，减少API调用
3. **速率限制**：API调用有速率限制，避免被限制
4. **重试机制**：网络错误时自动重试

### 数据库优化

1. **使用REPLACE INTO**：避免重复键错误
2. **批量写入**：减少数据库写入次数
3. **连接池**：复用数据库连接

### 下载策略优化

1. **混合方案**：默认只补全完全缺失的日期，定期全量校验
2. **批量API调用**：一次调用下载整个交易日的数据
3. **内存优化**：分批处理数据，避免内存溢出

## 常见使用场景

### 日常运行
```bash
# 每天晚上运行，使用安静模式
python main.py --log-level quiet
```

### 调试问题
```bash
# 详细模式查看所有信息
python main.py --log-level verbose
```

### 仅更新数据
```bash
# 只下载新数据，不重新计算指标
python main.py --download-only
```

### 重新计算指标
```bash
# 只重新计算技术指标
python main.py --process-only
```

### 跳过其他市场数据
```bash
# 只下载股票日线数据，跳过其他市场数据
python main.py --skip-other-data
```

## 常见问题

### Q: 程序运行时日志太多怎么办？
A: 使用安静模式运行：
```bash
python main.py --log-level quiet
```

### Q: 想要查看详细的调试信息？
A: 使用详细模式运行：
```bash
python main.py --log-level verbose
```

### Q: 如何保存日志到文件？
A: 使用--log-file参数：
```bash
python main.py --log-file logs/process.log
```

### Q: 程序运行很慢？
A: 这是正常的，因为：
1. 增量下载需要检查每个交易日的缺失数据
2. API调用有速率限制
3. 数据库写入需要时间

### Q: 新的下载策略有什么优势？
A: 新的混合方案 + 批量下载策略有以下优势：
1. **效率更高**：批量下载比逐个股票下载快很多
2. **避免重复**：只下载完全缺失的交易日，避免重复下载
3. **API调用更少**：一次调用下载整个交易日的数据
4. **数据完整性更好**：确保每个交易日的数据都是完整的
5. **智能检测**：自动识别哪些日期需要下载

### Q: 如果有个别股票数据缺失怎么办？
A: 系统采用混合方案：
1. **默认模式**：只补全完全缺失的交易日
2. **定期校验**：建议每月进行一次全量校验，补全个别缺失的数据
3. **手动补全**：如有特殊需求，可以手动运行全量下载

### Q: 其他市场数据包括哪些？
A: 其他市场数据包括：
1. **资金流向数据**：大盘资金流向、板块资金流向
2. **交易数据**：龙虎榜数据、机构交易数据
3. **概念数据**：概念成分股、概念数据
4. **排名数据**：各种股票排名数据

### Q: 如何跳过其他市场数据下载？
A: 使用--skip-other-data参数：
```bash
python main.py --skip-other-data
```

## 定时任务设置

使用 `setup_scheduler.py` 设置定时任务：

```bash
python setup_scheduler.py
```

默认设置为每天晚上7点运行。

## 注意事项

1. **网络连接**：确保网络连接稳定，API调用需要网络
2. **数据库连接**：确保MySQL数据库运行正常
3. **磁盘空间**：确保有足够的磁盘空间存储数据
4. **API限制**：注意Tushare API的调用限制
5. **数据完整性**：建议定期运行完整流程确保数据完整性

## 故障排除

### 如果遇到重复键错误
这是正常现象，系统会自动跳过重复数据。

### 如果程序卡住
检查网络连接和数据库连接是否正常。

### 如果内存不足
可以调整 `BATCH_SIZE` 参数减少批量处理大小。

### 如果下载速度慢
这是正常的，因为：
1. Tushare API有速率限制
2. 批量下载需要处理大量数据
3. 数据库写入需要时间 